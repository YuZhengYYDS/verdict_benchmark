{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af3294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERDICT MLP Model Evaluation\n",
    "# This notebook evaluates the trained MLP model on patient brain data\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Import MLP model\n",
    "from models.mlp import MLPRegressor\n",
    "\n",
    "# Load the NIfTI file\n",
    "img = nib.load(r'D:\\AiProjects\\UCLmaster\\OneDrive_1_2025-5-2\\data\\Patient08\\Patient08_mc_normb0.nii.gz')\n",
    "data = img.get_fdata()\n",
    "\n",
    "print(\"=== VERDICT MLP Model Evaluation ===\")\n",
    "print(f\"Loaded brain data shape: {data.shape}\")\n",
    "print(f\"Data type: {data.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ddf47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (112, 112, 60, 153)\n",
      "Data type of data: float64\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "I = img.get_fdata().astype(np.float64)\n",
    "\n",
    "# Get image dimensions\n",
    "sx, sy, sz, vol = I.shape\n",
    "print(f\"Image dimensions: {sx} x {sy} x {sz}, Volumes: {vol}\")\n",
    "\n",
    "# Reshape image to 2D (voxels x volumes)\n",
    "ROI = I.reshape((sx * sy * sz, vol))\n",
    "print(f\"ROI shape after reshape: {ROI.shape}\")\n",
    "\n",
    "# Clean the signal: remove nan, inf, and negative values\n",
    "signal = np.nan_to_num(ROI, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "signal[signal < 0] = 0\n",
    "\n",
    "# Keep all voxels to preserve spatial structure\n",
    "signal_filtered = signal\n",
    "print(f\"Total voxels: {signal_filtered.shape[0]:,}\")\n",
    "print(f\"Non-zero voxels: {np.count_nonzero(np.any(signal_filtered > 0, axis=1)):,}\")\n",
    "print(f\"Signal range: [{signal_filtered.min():.3f}, {signal_filtered.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d369de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (112, 112, 60, 153)\n"
     ]
    }
   ],
   "source": [
    "# Load MLP model and scaler\n",
    "def load_mlp_model():\n",
    "    \"\"\"Load the trained MLP model and its scaler\"\"\"\n",
    "    checkpoint_dir = r'd:\\AiProjects\\verdict_benchmark\\checkpoints'\n",
    "    \n",
    "    # Load model\n",
    "    model = MLPRegressor(input_dim=153, output_dim=8, \n",
    "                        hidden_dims=[150, 150, 150], activation='relu')\n",
    "    \n",
    "    model_path = os.path.join(checkpoint_dir, 'mlp_best.pt')\n",
    "    if os.path.exists(model_path):\n",
    "        state_dict = torch.load(model_path, map_location='cpu', weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        print(\"✓ Loaded MLP model successfully\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    # Load scaler\n",
    "    scaler_path = os.path.join(checkpoint_dir, 'mlp_scaler.pkl')\n",
    "    if os.path.exists(scaler_path):\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            scaler = pickle.load(f)\n",
    "        print(\"✓ Loaded MLP scaler successfully\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Scaler file not found: {scaler_path}\")\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "# Load the MLP model and scaler\n",
    "mlp_model, mlp_scaler = load_mlp_model()\n",
    "print(f\"Model parameters: {sum(p.numel() for p in mlp_model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac4d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: 112 x 112 x 60, Volumes: 153\n",
      "ROI shape after reshape: (752640, 153)\n",
      "ROI shape after reshape: (752640, 153)\n"
     ]
    }
   ],
   "source": [
    "# Define VERDICT parameter names\n",
    "param_names = ['fic', 'fee', 'Dic', 'R', 'Dpar', 'Dtra', 'theta', 'phi']\n",
    "print(f\"VERDICT parameters: {param_names}\")\n",
    "\n",
    "# Run MLP inference on all voxels\n",
    "print(\"\\n=== Running MLP Inference ===\")\n",
    "\n",
    "# Get non-zero voxels for processing\n",
    "non_zero_mask = np.any(signal_filtered > 0, axis=1)\n",
    "signal_nonzero = signal_filtered[non_zero_mask]\n",
    "print(f\"Processing {signal_nonzero.shape[0]:,} non-zero voxels...\")\n",
    "\n",
    "# Process in batches to avoid memory issues\n",
    "batch_size = 1000\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, signal_nonzero.shape[0], batch_size):\n",
    "        batch = signal_nonzero[i:i+batch_size]\n",
    "        batch_tensor = torch.FloatTensor(batch)\n",
    "        \n",
    "        # Get scaled predictions from model\n",
    "        batch_pred_scaled = mlp_model(batch_tensor)\n",
    "        \n",
    "        # Inverse transform to get real parameter values\n",
    "        batch_pred = mlp_scaler.inverse_transform(batch_pred_scaled.numpy())\n",
    "        all_predictions.append(batch_pred)\n",
    "        \n",
    "        if (i // batch_size + 1) % 20 == 0:\n",
    "            print(f\"  Processed {i + batch.shape[0]:,} voxels...\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "predictions_p1_p8 = np.concatenate(all_predictions, axis=0)\n",
    "print(f\"✓ Completed MLP inference!\")\n",
    "print(f\"Predictions shape: {predictions_p1_p8.shape}\")\n",
    "print(f\"Parameter range: [{predictions_p1_p8.min():.4f}, {predictions_p1_p8.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8174197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal shape: (752640, 153)\n",
      "Signal data type: float64\n"
     ]
    }
   ],
   "source": [
    "# Transform model outputs (p1-p8) to actual VERDICT parameters\n",
    "print(\"\\n=== Parameter Transformation ===\")\n",
    "\n",
    "# Apply transformations to get actual VERDICT parameters\n",
    "predictions_verdict = np.zeros_like(predictions_p1_p8)\n",
    "\n",
    "# fic = cos(p1)^2\n",
    "predictions_verdict[:, 0] = np.cos(predictions_p1_p8[:, 0])**2\n",
    "\n",
    "# fee = (1-cos(p1)^2)*cos(p2)^2 = sin(p1)^2 * cos(p2)^2  \n",
    "predictions_verdict[:, 1] = (1 - np.cos(predictions_p1_p8[:, 0])**2) * np.cos(predictions_p1_p8[:, 1])**2\n",
    "\n",
    "# Dic = p3 (Intracellular diffusivity)\n",
    "predictions_verdict[:, 2] = predictions_p1_p8[:, 2]\n",
    "\n",
    "# R = p4 (Cell radius)\n",
    "predictions_verdict[:, 3] = predictions_p1_p8[:, 3]\n",
    "\n",
    "# Dpar = p5 (Parallel diffusivity)\n",
    "predictions_verdict[:, 4] = predictions_p1_p8[:, 4]\n",
    "\n",
    "# Dtra = p6*p5 (Transverse diffusivity)\n",
    "predictions_verdict[:, 5] = predictions_p1_p8[:, 5] * predictions_p1_p8[:, 4]\n",
    "\n",
    "# theta = p7 (Polar angle)\n",
    "predictions_verdict[:, 6] = predictions_p1_p8[:, 6]\n",
    "\n",
    "# phi = p8 (Azimuthal angle)\n",
    "predictions_verdict[:, 7] = predictions_p1_p8[:, 7]\n",
    "\n",
    "print(\"✓ Parameter transformation completed!\")\n",
    "print(f\"Transformed VERDICT range: [{predictions_verdict.min():.6f}, {predictions_verdict.max():.6f}]\")\n",
    "\n",
    "# Use transformed values for all analysis\n",
    "predictions_mlp = predictions_verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8eefc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total voxels kept: 752640\n",
      "Signal shape: (752640, 153)\n",
      "Non-zero voxels: 150682\n",
      "Zero voxels: 601958\n"
     ]
    }
   ],
   "source": [
    "# Create 3D prediction volume for visualization\n",
    "print(\"\\n=== Creating 3D Visualization Volume ===\")\n",
    "\n",
    "# Initialize full volume with zeros\n",
    "prediction_volume = np.zeros((sx * sy * sz, 8))\n",
    "\n",
    "# Fill in predictions for non-zero voxels\n",
    "prediction_volume[non_zero_mask] = predictions_mlp\n",
    "\n",
    "# Reshape to 3D volume\n",
    "prediction_3d = prediction_volume.reshape((sx, sy, sz, 8))\n",
    "\n",
    "# Define middle slices for visualization\n",
    "mid_slice_axial = sz // 2\n",
    "mid_slice_coronal = sy // 2\n",
    "mid_slice_sagittal = sx // 2\n",
    "\n",
    "print(f\"3D volume shape: {prediction_3d.shape}\")\n",
    "print(f\"Middle slices - Axial: {mid_slice_axial}, Coronal: {mid_slice_coronal}, Sagittal: {mid_slice_sagittal}\")\n",
    "print(\"✓ 3D volume ready for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651bb88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing signal with shape: (752640, 153)\n",
      "Non-zero voxels: 150682\n",
      "Data range: [0.000, 1.999]\n"
     ]
    }
   ],
   "source": [
    "# Visualization 1: Brain Parameter Maps\n",
    "print(\"\\n=== Brain Parameter Maps ===\")\n",
    "plt.style.use('default')\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle('VERDICT MRI Parameter Maps - Axial View (MLP Model)', fontsize=16, y=0.95)\n",
    "\n",
    "for i in range(8):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    param_slice = prediction_3d[:, :, mid_slice_axial, i]\n",
    "    im = ax.imshow(param_slice, cmap='viridis', aspect='equal')\n",
    "    ax.set_title(f'{param_names[i]}\\n(Axial slice {mid_slice_axial})', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb823b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERDICT parameters: ['fic', 'fee', 'Dic', 'R', 'Dpar', 'Dtra', 'theta', 'phi']\n"
     ]
    }
   ],
   "source": [
    "# Visualization 2: Parameter Statistical Analysis\n",
    "print(\"\\n=== Parameter Statistical Analysis ===\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 2a. Parameter distribution histograms (first 4)\n",
    "ax = axes[0, 0]\n",
    "for i in range(4):\n",
    "    ax.hist(predictions_mlp[:, i], alpha=0.6, bins=50, label=param_names[i])\n",
    "ax.set_xlabel('Parameter Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Parameter Distributions (Volume Fractions & Diffusivity)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2b. Parameter distribution histograms (last 4)\n",
    "ax = axes[0, 1]\n",
    "for i in range(4, 8):\n",
    "    ax.hist(predictions_mlp[:, i], alpha=0.6, bins=50, label=param_names[i])\n",
    "ax.set_xlabel('Parameter Value')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Parameter Distributions (Geometry & Orientation)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2c. Parameter correlation matrix\n",
    "ax = axes[1, 0]\n",
    "correlation_matrix = np.corrcoef(predictions_mlp.T)\n",
    "im = ax.imshow(correlation_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "ax.set_title('Parameter Correlation Matrix')\n",
    "ax.set_xticks(range(8))\n",
    "ax.set_xticklabels(param_names, rotation=45, ha='right')\n",
    "ax.set_yticks(range(8))\n",
    "ax.set_yticklabels(param_names)\n",
    "cbar = plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# Add correlation values\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax.text(j, i, f'{correlation_matrix[i, j]:.2f}', \n",
    "                ha='center', va='center', fontsize=8,\n",
    "                color='white' if abs(correlation_matrix[i, j]) > 0.5 else 'black')\n",
    "\n",
    "# 2d. Box plots for parameter ranges\n",
    "ax = axes[1, 1]\n",
    "box_data = [predictions_mlp[:, i] for i in range(8)]\n",
    "bp = ax.boxplot(box_data, labels=param_names, patch_artist=True)\n",
    "for patch in bp['boxes']:\n",
    "    patch.set_facecolor('lightblue')\n",
    "    patch.set_alpha(0.7)\n",
    "ax.set_ylabel('Parameter Value')\n",
    "ax.set_title('Parameter Value Ranges')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['mlp', 'cnn', 'residual_mlp', 'rnn', 'transformer', 'moe_regressor', 'vae_regressor', 'tabnet_regressor']\n"
     ]
    }
   ],
   "source": [
    "# Visualization 3: Multi-orientation Brain Views (fIC parameter)\n",
    "print(\"\\n=== Multi-orientation Brain Views ===\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Intracellular Volume Fraction (fIC) - Multiple Brain Views', fontsize=16, y=0.95)\n",
    "\n",
    "# 3a. Axial view\n",
    "ax = axes[0, 0]\n",
    "axial_slice = prediction_3d[:, :, mid_slice_axial, 0]\n",
    "im = ax.imshow(axial_slice, cmap='viridis', aspect='equal')\n",
    "ax.set_title(f'Axial View (slice {mid_slice_axial})')\n",
    "ax.axis('off')\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# 3b. Coronal view\n",
    "ax = axes[0, 1]\n",
    "coronal_slice = prediction_3d[:, mid_slice_coronal, :, 0]\n",
    "im = ax.imshow(coronal_slice.T, cmap='viridis', aspect='auto', origin='lower')\n",
    "ax.set_title(f'Coronal View (slice {mid_slice_coronal})')\n",
    "ax.set_xlabel('X direction')\n",
    "ax.set_ylabel('Z direction')\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# 3c. Sagittal view\n",
    "ax = axes[1, 0]\n",
    "sagittal_slice = prediction_3d[mid_slice_sagittal, :, :, 0]\n",
    "im = ax.imshow(sagittal_slice.T, cmap='viridis', aspect='auto', origin='lower')\n",
    "ax.set_title(f'Sagittal View (slice {mid_slice_sagittal})')\n",
    "ax.set_xlabel('Y direction')\n",
    "ax.set_ylabel('Z direction')\n",
    "plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "\n",
    "# 3d. Brain mask overlay\n",
    "ax = axes[1, 1]\n",
    "brain_mask = np.any(prediction_3d > 0, axis=3)\n",
    "brain_slice = brain_mask[:, :, mid_slice_axial]\n",
    "ax.imshow(brain_slice, cmap='gray', aspect='equal')\n",
    "ax.set_title(f'Brain Tissue Mask (Axial slice {mid_slice_axial})')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aec198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model architecture from weights:\n",
      "Input dim: 153\n",
      "Hidden layers: torch.Size([150, 150])\n",
      "Output dim: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yz237\\AppData\\Local\\Temp\\ipykernel_41116\\2053773081.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(r'd:\\AiProjects\\verdict_benchmark\\checkpoints\\mlp_best.pt', map_location='cpu')\n"
     ]
    }
   ],
   "source": [
    "# Visualization 4: Summary Statistics and Analysis\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('VERDICT Parameter Analysis Summary', fontsize=16, y=0.95)\n",
    "\n",
    "# 4a. Signal quality metrics\n",
    "ax = axes[0, 0]\n",
    "signal_std = np.std(signal_nonzero, axis=1)\n",
    "signal_mean = np.mean(signal_nonzero, axis=1)\n",
    "signal_cv = signal_std / (signal_mean + 1e-8)\n",
    "\n",
    "scatter = ax.scatter(signal_mean, signal_cv, alpha=0.5, s=1, c='blue')\n",
    "ax.set_xlabel('Signal Mean')\n",
    "ax.set_ylabel('Coefficient of Variation')\n",
    "ax.set_title('Signal Quality Assessment')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4b. Parameter means comparison\n",
    "ax = axes[0, 1]\n",
    "param_means = [predictions_mlp[:, i].mean() for i in range(8)]\n",
    "param_stds = [predictions_mlp[:, i].std() for i in range(8)]\n",
    "bars = ax.bar(param_names, param_means, yerr=param_stds, capsize=5, alpha=0.7, color='green')\n",
    "ax.set_xlabel('Parameters')\n",
    "ax.set_ylabel('Mean Value ± Std')\n",
    "ax.set_title('Parameter Summary Statistics')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels with appropriate precision\n",
    "for i, (bar, mean, std) in enumerate(zip(bars, param_means, param_stds)):\n",
    "    if param_names[i] in ['Dic', 'R', 'Dpar', 'Dtra']:\n",
    "        label = f'{mean:.6f}'\n",
    "    else:\n",
    "        label = f'{mean:.3f}'\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.02, \n",
    "             label, ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4c. Parameter ranges visualization\n",
    "ax = axes[1, 0]\n",
    "param_mins = [predictions_mlp[:, i].min() for i in range(8)]\n",
    "param_maxs = [predictions_mlp[:, i].max() for i in range(8)]\n",
    "\n",
    "x_pos = np.arange(8)\n",
    "for i in range(8):\n",
    "    ax.errorbar(x_pos[i], param_means[i], \n",
    "                yerr=[[param_means[i] - param_mins[i]], [param_maxs[i] - param_means[i]]], \n",
    "                fmt='o', capsize=5, markersize=8)\n",
    "\n",
    "ax.set_xlabel('Parameters')\n",
    "ax.set_ylabel('Value Range')\n",
    "ax.set_title('Parameter Value Ranges (Min-Max)')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(param_names, rotation=45, ha='right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4d. Summary statistics table\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "\n",
    "stats_text = \"VERDICT Parameter Statistics Summary:\\n\\n\"\n",
    "stats_text += f\"{'Parameter':<8} {'Mean':<12} {'Std':<12} {'Min':<12} {'Max':<12}\\n\"\n",
    "stats_text += \"-\" * 65 + \"\\n\"\n",
    "\n",
    "for i, param in enumerate(param_names):\n",
    "    values = predictions_mlp[:, i]\n",
    "    if param in ['Dic', 'R', 'Dpar', 'Dtra']:\n",
    "        if values.mean() < 0.001:\n",
    "            stats_text += f\"{param:<8} {values.mean():<12.2e} {values.std():<12.2e} {values.min():<12.2e} {values.max():<12.2e}\\n\"\n",
    "        else:\n",
    "            stats_text += f\"{param:<8} {values.mean():<12.6f} {values.std():<12.6f} {values.min():<12.6f} {values.max():<12.6f}\\n\"\n",
    "    else:\n",
    "        stats_text += f\"{param:<8} {values.mean():<12.3f} {values.std():<12.3f} {values.min():<12.3f} {values.max():<12.3f}\\n\"\n",
    "\n",
    "stats_text += \"\\n\" + \"-\" * 65 + \"\\n\"\n",
    "stats_text += f\"Brain volume: {sx} × {sy} × {sz} = {sx*sy*sz:,} voxels\\n\"\n",
    "stats_text += f\"Brain tissue: {predictions_mlp.shape[0]:,} voxels ({100*predictions_mlp.shape[0]/(sx*sy*sz):.1f}%)\\n\"\n",
    "stats_text += f\"MLP Model: {sum(p.numel() for p in mlp_model.parameters()):,} parameters\\n\"\n",
    "\n",
    "ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=9,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ MLP Evaluation Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verdict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
