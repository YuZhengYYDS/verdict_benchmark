{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fabdd76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Torch version: 2.5.1+cu121\n",
      "[INFO] CUDA available: True\n",
      "[INFO] CUDA device: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# 1. 环境和依赖检查\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "print(\"[INFO] Torch version:\", torch.__version__)\n",
    "print(\"[INFO] CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"[INFO] CUDA device:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"[INFO] CUDA device not found, using CPU.\")\n",
    "\n",
    "# 安装 tqdm/scipy（如未安装时取消注释）\n",
    "# !pip install tqdm scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e90e7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 配置、模型和工具模块导入\n",
    "from data.dataset import get_dataloaders\n",
    "from models.mlp import MLPRegressor\n",
    "from utils.metrics import mse_loss\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ee0e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "配置内容： {'seed': 42, 'epochs': 100, 'batch_size': 64, 'lr': 0.001, 'hidden_dims': [150, 150, 150], 'activation': 'relu', 'train_ratio': 0.8, 'early_stop_patience': 10}\n"
     ]
    }
   ],
   "source": [
    "# 3. 加载配置\n",
    "cfg_path = \"configs/mlp.yaml\"\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "print(\"配置内容：\", cfg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ad8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 4. 设置随机种子与训练参数\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "set_seed(cfg['seed'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647329a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 训练/验证数据已准备好。\n"
     ]
    }
   ],
   "source": [
    "# 5. 数据加载\n",
    "scaler_path = \"checkpoints/mlp_minmaxscaler.pkl\"\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    mat_path='D:/AiProjects/UCLmaster/dlfitting_verdict/VERDICT_training/AS_Z_fixdv/TrainingSet.mat',\n",
    "    batch_size=cfg['batch_size'],\n",
    "    train_ratio=cfg['train_ratio'],\n",
    "    seed=cfg['seed'],\n",
    "    scaler_path=scaler_path\n",
    ")\n",
    "print(\"[INFO] 训练/验证数据已准备好。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163649a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 模型初始化完成。\n"
     ]
    }
   ],
   "source": [
    "# 6. 初始化模型和优化器\n",
    "X_sample, y_sample = next(iter(train_loader))\n",
    "input_dim = X_sample.shape[1]\n",
    "output_dim = y_sample.shape[1]\n",
    "model = MLPRegressor(input_dim, output_dim, cfg['hidden_dims'], cfg['activation']).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=cfg['lr'])\n",
    "criterion = torch.nn.MSELoss()\n",
    "print(\"[INFO] 模型初始化完成。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1409ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 日志与权重文件准备\n",
    "log_dir = 'logs'\n",
    "ckpt_dir = 'checkpoints'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(ckpt_dir, exist_ok=True)\n",
    "log_path = os.path.join(log_dir, 'mlp_log.txt')\n",
    "ckpt_path = os.path.join(ckpt_dir, 'mlp_best.pt')\n",
    "\n",
    "if not os.path.exists(log_path):\n",
    "    with open(log_path, 'w') as f:\n",
    "        f.write(\"Epoch\\tTrainLoss\\tValLoss\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abbb66e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEpoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yz237\\miniconda3\\envs\\verdict\\lib\\site-packages\\tqdm\\notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yz237\\miniconda3\\envs\\verdict\\lib\\site-packages\\tqdm\\notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[1;34m(_, total, desc, ncols)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[0;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[1;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "# 8. 训练主循环（带tqdm进度条）\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = cfg['epochs']\n",
    "best_loss = float('inf')\n",
    "patience = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X, y in tqdm(train_loader, desc=f\"Train {epoch+1}\", leave=False):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "    avg_train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # 验证\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "            total_val_loss += loss.item() * X.size(0)\n",
    "    avg_val_loss = total_val_loss / len(val_loader.dataset)\n",
    "\n",
    "    # tqdm.write会在进度条下方输出log，方便notebook观察\n",
    "    tqdm.write(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # 追加日志\n",
    "    with open(log_path, 'a') as f:\n",
    "        f.write(f\"{epoch+1}\\t{avg_train_loss:.6f}\\t{avg_val_loss:.6f}\\n\")\n",
    "\n",
    "    # Early stopping & best权重\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), ckpt_path)\n",
    "        tqdm.write(f\"[INFO] Best model saved at: {ckpt_path}\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= cfg['early_stop_patience']:\n",
    "            tqdm.write(\"[INFO] Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "print(\"训练完成！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verdict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
